{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithme de recommandation V1 \n",
    "\n",
    "### Dataset Entreprises : Kompass\n",
    "\n",
    "### Dataset Projets : Projets de Globedreamers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import des librairies \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, euclidean_distances, manhattan_distances\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommandation projets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du fichier excel\n",
    "df_projets = pd.read_excel(\"../Data/Projets/Liste-des-projets.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_projets_clean = df_projets[df_projets.columns[:-8]]\n",
    "\n",
    "df_projets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de la distribution des différents types de projets\n",
    "df_projets_clean.Engagement.value_counts().compress(lambda s: s>=1).plot(kind='bar') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supp les carac invalides\n",
    "df_projets_clean['Résumé'] = df_projets_clean.loc[:, 'Résumé'].replace(regex=True, to_replace=\"\\xa0\", value=\"\").replace(regex=True, to_replace=\"\\n\", value=\"\").replace(regex=True, to_replace=\"\\r\", value=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mets en majuscule tous les sponsors \n",
    "df_projets_clean['Sponsors'] = df_projets_clean['Sponsors'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algo de recommandation basé sur le résumé de chaque projet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si jamais on a des données NA on les remplace par ''\n",
    "#df_projets_clean.presentation = df_projets_clean.Résumé.fillna('')\n",
    "\n",
    "# Récupère la liste de stopwords français de NLTK\n",
    "stop_words = stopwords.words('french')\n",
    "# Ajoute la ponctuation dans la liste de stopwords\n",
    "stop_words.extend(list(string.punctuation))\n",
    "\n",
    "# Tokenize nos données et retire les stopwords\n",
    "tfidf_projet = TfidfVectorizer(stop_words=stop_words) \n",
    "\n",
    "# Applique les TF-IDF pour représenter les données\n",
    "tfidf_matrix_projets = tfidf_projet.fit_transform(df_projets_clean.Résumé) \n",
    "\n",
    "tfidf_matrix_projets.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map les titres des projets avec les index\n",
    "indices = pd.Series(df_projets_clean.index, index=df_projets_clean.Titre) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_projets(resume, distance):\n",
    "    '''\n",
    "    Retourne le titre et le sponsor du projet le plus similaire \n",
    "    Prend en parametre des données textuelles et une mesure de distance\n",
    "    '''\n",
    "    \n",
    "    resume = [resume]\n",
    "    \n",
    "    # vectorize les données grâce aux TF-IDF appris sur les résumés des projets \n",
    "    new_tfidf_matrix_projets = tfidf_projet.transform(resume)\n",
    "    \n",
    "    if distance == \"euclidean\":\n",
    "        distance_sim_projet = euclidean_distances(new_tfidf_matrix_projets, tfidf_matrix_projets) \n",
    "    elif distance == \"cosin\":\n",
    "        # calcul d'angles entre les vecteurs TF-IDF de chaque résumé pour trouver les résumés similaires\n",
    "        distance_sim_projet = linear_kernel(new_tfidf_matrix_projets, tfidf_matrix_projets)   \n",
    "    elif distance == \"manhattan\":\n",
    "        distance_sim_projet = manhattan_distances(new_tfidf_matrix_projets, tfidf_matrix_projets) \n",
    "    else :\n",
    "        print(\"Mauvaise mesure de distance\")\n",
    "        return\n",
    "    \n",
    "    sim_max = distance_sim_projet.max()\n",
    "    \n",
    "    # récupère l'index des résumés ayant le score de similarité le plus élevé \n",
    "    index = np.where(distance_sim_projet == sim_max)\n",
    "    \n",
    "    projet_titre = df_projets_clean.Titre.at[index[1][0]]\n",
    "    projet_sponsor = df_projets_clean.Sponsors.at[index[1][0]]\n",
    "\n",
    "    return projet_titre, projet_sponsor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_projet = \"Voyage centré sur la protection de la faune sauvage pour sensibiliser les populations\"\n",
    "projet, sponsor = get_recommendations_projets(resume_projet,\"cosin\")\n",
    "print(projet,\" | \", sponsor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Recommandation entreprises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problème lié au dataset :\n",
    "    - Rajouter une virgule entre chaque document json et encapsuler le tout avec des \"[]\"\n",
    "    - Pour l'encodage convertir en ANSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# données d'entreprises sur les secteurs assurance et voyage\n",
    "with open(\"../Data/Entreprises/globedreamersAssuranceVoyage.json\") as datafile:\n",
    "    data = json.load(datafile)\n",
    "df_assurance_voyages = pd.DataFrame(data)\n",
    "df_assurance_voyages['category'] = 'Assurance_Voyage'\n",
    "print(df_assurance_voyages.shape)\n",
    "\n",
    "# données d'entreprises sur 9 autres secteurs\n",
    "with open(\"../Data/Entreprises/globedreamersDataset.json\") as datafile:\n",
    "    data = json.load(datafile)\n",
    "df_entreprise = pd.DataFrame(data)\n",
    "print(df_entreprise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_entreprise, df_assurance_voyages], sort=True)\n",
    "df = df.reset_index()\n",
    "df = df.drop(['index'], axis=1)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualisation de la distribution des entreprises par secteur\n",
    "df.category.value_counts().compress(lambda s: s>=1).plot(kind='bar') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Certaines entreprises sont présente dans plusieurs secteurs \n",
    "df[df.title == \"SODEXO JUSTICE SERVICES\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On supp tous les doublons d'entreprises \n",
    "df_clean = df.drop_duplicates(subset='title', keep=\"first\") \n",
    "df_clean = df_clean.reset_index(drop=True)\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Supp les carac invalides\n",
    "df_clean['presentation'] = df_clean.loc[:, 'presentation'].replace(regex=True, to_replace=\"\\xa0\", value=\"\").replace(regex=True, to_replace=\"\\n\", value=\"\").replace(regex=True, to_replace=\"\\r\", value=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean la variable capital\n",
    "df_clean['capital'] = df_clean.loc[:, 'capital'].replace(regex=True, to_replace=\"\\\"\", value=\"\").replace(regex=True, to_replace=\"EUR\", value=\"\").replace(regex=True, to_replace=\"CHF\", value=\"\").replace(regex=True, to_replace=\"\\s\", value=\"\")\n",
    "\n",
    "if 'capital' in df_clean.columns:\n",
    "    for i in range((len(df_clean.capital))):\n",
    "        if df_clean.capital.at[i] != '' and pd.isnull(df_clean.capital.at[i]) == False and not int:\n",
    "            df_clean.capital.at[i] = int(df_clean.capital.at[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# même processus que pour les projets\n",
    "df_clean.presentation = df_clean.presentation.fillna('')\n",
    "stop_words = stopwords.words('french')\n",
    "stop_words.extend(list(string.punctuation))\n",
    "\n",
    "# Tokenize les données et retire les stopwords\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words) \n",
    "\n",
    "# Applique les TF-IDF pour représenter les données\n",
    "tfidf_matrix_entreprise = tfidf.fit_transform(df_clean.presentation) \n",
    "\n",
    "tfidf_matrix_entreprise.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map les titres des entreprises avec les index\n",
    "indices = pd.Series(df_clean.index, index=df_clean.title) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_entreprises(title, distance):\n",
    "    '''\n",
    "    Retourne une dataframe avec la liste des entreprises recommandées\n",
    "    Prend en paramètre le titre d'une entreprise et la mesure de distance\n",
    "    '''\n",
    "    \n",
    "    # recup les index du titre grace au map juste avant\n",
    "    idx = indices[title]\n",
    "    \n",
    "    if distance == \"euclidean\":\n",
    "        distance_sim_entreprise = euclidean_distances(tfidf_matrix_entreprise, tfidf_matrix_entreprise) \n",
    "    elif distance == \"cosin\":\n",
    "        # calcul d'angles entre les vecteurs TF-IDF de chaque présentation pour trouver les présentations similaires\n",
    "        distance_sim_entreprise = linear_kernel(tfidf_matrix_entreprise, tfidf_matrix_entreprise)   \n",
    "    elif distance == \"manhattan\":\n",
    "        distance_sim_entreprise = manhattan_distances(tfidf_matrix_entreprise, tfidf_matrix_entreprise) \n",
    "    else :\n",
    "        print(\"Mauvaise mesure de distance\")\n",
    "        return\n",
    "\n",
    "    # recup les scores de similarité de tous les autres entreprises par rapport a celle en paramètre\n",
    "    sim_scores = list(enumerate(distance_sim_entreprise[idx]))\n",
    "\n",
    "    # trie les entreprises par score\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # top 10 des plus similaires (le 1er est forcement lui meme donc on commence à l'index 1)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # recup les index des entreprises avec les meilleurs score\n",
    "    idx_entreprises = [i[0] for i in sim_scores]\n",
    "\n",
    "    return df_clean.title.iloc[idx_entreprises].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tab = get_recommendations_entreprises(sponsor,\"cosin\")\n",
    "\n",
    "dfdf = pd.DataFrame({\"Entreprises_recommandées\" : tab})\n",
    "dfdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation_global(resume,distance_):\n",
    "    projet, sponsor = get_recommendations_projets(resume,distance_)\n",
    "    print(\"** Projet le plus similaire : \",projet)\n",
    "    print(\"** Son sponsor : \",sponsor),print()\n",
    "    print(\"** Recommandation à partir de : \",sponsor),print()\n",
    "    l_entreprises = get_recommendations_entreprises(sponsor,distance_)\n",
    "    dfdf = pd.DataFrame({\"Entreprises_recommandées\" : l_entreprises})\n",
    "    return dfdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_projet = \"Nous souhaitons à travers des photos mettre en avant le sens d'humanité à l'état brut, comprendre la nouvelle vie pour ces personnes qui y trouvent harmonie, et nous en inspirer. Nous souhaitons passer du temps avec ces gens, apprendre de leur choix de vie et de liberté, et le partager par le biais de nos photographies.\"\n",
    "print(\"** Nouveau projet :\"),print(resume_projet), print()\n",
    "df_reco = get_recommendation_global(resume_projet,\"cosin\")\n",
    "df_reco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
